{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "442ab029-65ac-4432-9125-93a97f875652",
   "metadata": {},
   "source": [
    "# SpaCy\n",
    "spaCy is another popular library for Natural Language Processing (NLP) that is designed for production use. It offers a wide range of functionalities for working with text, tokens, entities, and more. Below is a list of key functions and features inside the **spaCy** library:\n",
    "\n",
    "### 1. **Core Functions in spaCy**:\n",
    "   - **`spacy.load()`**: Loads a spaCy model.\n",
    "     ```python\n",
    "     nlp = spacy.load(\"en_core_web_sm\")\n",
    "     ```\n",
    "   - **`nlp()`**: Processes text with a loaded spaCy model.\n",
    "     ```python\n",
    "     doc = nlp(\"This is a sentence.\")\n",
    "     ```\n",
    "\n",
    "### 2. **Tokenization and Text Processing**:\n",
    "   - **`Doc`**: The core data structure, representing a processed document.\n",
    "   - **`Token`**: Represents individual tokens in a document.\n",
    "     ```python\n",
    "     for token in doc:\n",
    "         print(token.text, token.pos_, token.dep_)\n",
    "     ```\n",
    "   - **`Span`**: A slice of a `Doc` (multiple tokens).\n",
    "   - **`.sents`**: Accesses the sentences in a document.\n",
    "     ```python\n",
    "     for sent in doc.sents:\n",
    "         print(sent.text)\n",
    "     ```\n",
    "   - **`.ents`**: Extracts named entities.\n",
    "     ```python\n",
    "     for ent in doc.ents:\n",
    "         print(ent.text, ent.label_)\n",
    "     ```\n",
    "\n",
    "### 3. **Linguistic Features**:\n",
    "   - **`.lemma_`**: Lemmatizes a token.\n",
    "   - **`.pos_`**: Part-of-speech tagging of a token.\n",
    "   - **`.dep_`**: Dependency parsing (grammatical relations).\n",
    "   - **`.is_alpha`**, **`.is_stop`**: Checks if a token is alphabetic or a stopword.\n",
    "   - **`.shape_`**: Returns the shape of the token (e.g., capitalized, etc.).\n",
    "\n",
    "### 4. **Named Entity Recognition (NER)**:\n",
    "   - **`.ents`**: Extracts named entities.\n",
    "     ```python\n",
    "     for ent in doc.ents:\n",
    "         print(ent.text, ent.label_)\n",
    "     ```\n",
    "   - **`spacy.explain()`**: Provides explanations of labels (POS, NER, etc.).\n",
    "     ```python\n",
    "     spacy.explain(\"ORG\")\n",
    "     ```\n",
    "\n",
    "### 5. **Text Classification**:\n",
    "   - **`.cats`**: Used to access the document categories.\n",
    "   - **`.textcat`**: Built-in text classifier (in spaCy v3.0 and later).\n",
    "\n",
    "### 6. **Vector Representations**:\n",
    "   - **`.vector`**: Retrieves word vectors (embeddings) for tokens and documents.\n",
    "   - **`.similarity()`**: Computes similarity between documents or tokens based on word vectors.\n",
    "     ```python\n",
    "     similarity_score = doc1.similarity(doc2)\n",
    "     ```\n",
    "\n",
    "### 7. **Pipeline Components**:\n",
    "   - **`nlp.pipe()`**: Efficiently processes a batch of texts.\n",
    "     ```python\n",
    "     for doc in nlp.pipe([\"Sentence 1\", \"Sentence 2\"]):\n",
    "         print(doc)\n",
    "     ```\n",
    "   - **`nlp.add_pipe()`**: Adds a custom component to the pipeline.\n",
    "   - **`nlp.remove_pipe()`**: Removes a component from the pipeline.\n",
    "   - **`nlp.get_pipe()`**: Retrieves a specific pipeline component.\n",
    "   - **`nlp.pipeline`**: Lists all the components in the pipeline.\n",
    "     ```python\n",
    "     print(nlp.pipeline)\n",
    "     ```\n",
    "\n",
    "### 8. **Pattern Matching**:\n",
    "   - **`Matcher`**: A rule-based token matcher.\n",
    "     ```python\n",
    "     from spacy.matcher import Matcher\n",
    "     matcher = Matcher(nlp.vocab)\n",
    "     ```\n",
    "   - **`PhraseMatcher`**: Matches exact sequences of tokens.\n",
    "   - **`DependencyMatcher`**: Matches based on the syntactic dependency structure.\n",
    "\n",
    "### 9. **Visualization**:\n",
    "   - **`displacy.render()`**: Visualizes the dependency tree or named entities in a document.\n",
    "     ```python\n",
    "     from spacy import displacy\n",
    "     displacy.render(doc, style=\"dep\")\n",
    "     ```\n",
    "   - **`displacy.serve()`**: Serves visualizations via a web browser.\n",
    "     ```python\n",
    "     displacy.serve(doc, style=\"dep\")\n",
    "     ```\n",
    "\n",
    "### 10. **Training and Fine-tuning**:\n",
    "   - **`spacy.training`**: Tools for model training and evaluation.\n",
    "   - **`spacy.train()`**: Training models from scratch.\n",
    "   - **`spacy.evaluate()`**: Evaluating a trained model.\n",
    "\n",
    "### 11. **Language Models**:\n",
    "   - **`Language`**: The core class for NLP pipelines.\n",
    "   - **`Vocab`**: Stores the vocabulary of a language.\n",
    "   - **`Tokenizer`**: Handles tokenization.\n",
    "   - **`Tagger`**, **`Parser`**, **`EntityRecognizer`**: Various pipeline components.\n",
    "\n",
    "### 12. **Data Management**:\n",
    "   - **`spacy.blank()`**: Creates a blank language model for custom NLP tasks.\n",
    "     ```python\n",
    "     nlp = spacy.blank(\"en\")\n",
    "     ```\n",
    "   - **`spacy.read_vectors()`**: Reads word vectors.\n",
    "   - **`DocBin`**: Serializes `Doc` objects for storage.\n",
    "\n",
    "### 13. **Word Vectors & Embeddings**:\n",
    "   - **`.vector`**: Retrieves word vectors for tokens and docs.\n",
    "     ```python\n",
    "     doc[0].vector\n",
    "     ```\n",
    "   - **`.similarity()`**: Computes similarity between documents, spans, or tokens based on vectors.\n",
    "     ```python\n",
    "     doc1.similarity(doc2)\n",
    "     ```\n",
    "\n",
    "### 14. **Custom Components & Extensions**:\n",
    "   - **`@Language.component()`**: Allows you to create custom pipeline components.\n",
    "     ```python\n",
    "     @Language.component(\"custom_component\")\n",
    "     def custom_component(doc):\n",
    "         return doc\n",
    "     ```\n",
    "   - **`.set_extension()`**: Creates custom attributes for `Doc`, `Span`, or `Token`.\n",
    "     ```python\n",
    "     Token.set_extension(\"is_custom\", default=False)\n",
    "     ```\n",
    "\n",
    "### 15. **Documentation and Model Loading**:\n",
    "   - **`spacy.info()`**: Provides information about the installed spaCy models and the environment.\n",
    "   - **`spacy.util`**: Contains various utility functions for handling files, I/O, and more.\n",
    "   - **`spacy.load()`**: Loads a pre-trained model (as mentioned earlier).\n",
    "\n",
    "### 16. **Evaluation Metrics**:\n",
    "   - **`spacy.scorer`**: Tools for calculating precision, recall, and F-scores for tasks like Named Entity Recognition (NER).\n",
    "\n",
    "### 17. **Additional Tools and Utilities**:\n",
    "   - **`spacy.gold`**: Handles annotated gold-standard data.\n",
    "   - **`spacy.about`**: Provides information about the spaCy version and authors.\n",
    "   - **`spacy.cli`**: Command-line tools for managing spaCy resources.\n",
    "\n",
    "---\n",
    "\n",
    "### To explore more functions and details:\n",
    "- **Use the `help()` function**:\n",
    "  ```python\n",
    "  import spacy\n",
    "  help(spacy)\n",
    "  ```\n",
    "\n",
    "- **Check the official spaCy documentation**:\n",
    "  Visit the [spaCy documentation](https://spacy.io/api) for a detailed API reference and function list.\n",
    "\n",
    "The exact list of functions will vary based on your spaCy version and any extensions or custom components you may add, but this covers most of the core functionalities provided by spaCy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb31a8a-5d16-4068-b3de-b8b9fc94c156",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
