{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b73500cc-450b-46ce-b170-aab690ce5b8a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character '’' (U+2019) (2842552178.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    The **NLTK (Natural Language Toolkit)** library provides a wide range of functions to perform different NLP tasks. Here’s a categorized list of some commonly used functions and modules in the NLTK library:\u001b[0m\n\u001b[0m                                                                                                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character '’' (U+2019)\n"
     ]
    }
   ],
   "source": [
    "The **NLTK (Natural Language Toolkit)** library provides a wide range of functions to perform different NLP tasks. Here’s a categorized list of some commonly used functions and modules in the NLTK library:\n",
    "\n",
    "### 1. **Tokenization**:\n",
    "   - **Word Tokenization**: Splits text into words.\n",
    "     ```python\n",
    "     nltk.word_tokenize(text)\n",
    "     ```\n",
    "   - **Sentence Tokenization**: Splits text into sentences.\n",
    "     ```python\n",
    "     nltk.sent_tokenize(text)\n",
    "     ```\n",
    "\n",
    "### 2. **Stemming**:\n",
    "   - **PorterStemmer**: Reduces words to their root form.\n",
    "     ```python\n",
    "     from nltk.stem import PorterStemmer\n",
    "     ps = PorterStemmer()\n",
    "     ps.stem(word)\n",
    "     ```\n",
    "   - **LancasterStemmer**: A more aggressive stemmer.\n",
    "     ```python\n",
    "     from nltk.stem import LancasterStemmer\n",
    "     ls = LancasterStemmer()\n",
    "     ls.stem(word)\n",
    "     ```\n",
    "\n",
    "### 3. **Lemmatization**:\n",
    "   - **WordNet Lemmatizer**: Uses WordNet to reduce words to their base form.\n",
    "     ```python\n",
    "     from nltk.stem import WordNetLemmatizer\n",
    "     lemmatizer = WordNetLemmatizer()\n",
    "     lemmatizer.lemmatize(word, pos='v')  # specify part of speech\n",
    "     ```\n",
    "\n",
    "### 4. **Part-of-Speech Tagging**:\n",
    "   - **POS Tagger**: Tags words with their part of speech.\n",
    "     ```python\n",
    "     nltk.pos_tag(tokens)\n",
    "     ```\n",
    "\n",
    "### 5. **Named Entity Recognition (NER)**:\n",
    "   - **Chunking Named Entities**: Identifies named entities in a sentence.\n",
    "     ```python\n",
    "     nltk.ne_chunk(nltk.pos_tag(tokens))\n",
    "     ```\n",
    "\n",
    "### 6. **Parsing & Tree Structures**:\n",
    "   - **Recursive Descent Parser**: A parser for analyzing the syntactic structure.\n",
    "     ```python\n",
    "     nltk.RecursiveDescentParser(grammar)\n",
    "     ```\n",
    "   - **Dependency Parsing**: Analyzing relationships between words.\n",
    "     ```python\n",
    "     nltk.parse.DependencyGraph()\n",
    "     ```\n",
    "\n",
    "### 7. **Stopwords**:\n",
    "   - **Stopwords**: Provides a list of common stopwords (words like “the,” “is,” etc.).\n",
    "     ```python\n",
    "     from nltk.corpus import stopwords\n",
    "     stop_words = set(stopwords.words('english'))\n",
    "     ```\n",
    "\n",
    "### 8. **Frequency Distribution**:\n",
    "   - **Counting Word Frequency**: Analyzes the frequency of tokens in text.\n",
    "     ```python\n",
    "     from nltk import FreqDist\n",
    "     fdist = FreqDist(tokens)\n",
    "     fdist.most_common(n)  # Top n most common words\n",
    "     ```\n",
    "\n",
    "### 9. **N-Grams**:\n",
    "   - **Generating N-Grams**: Create n-grams (bigrams, trigrams, etc.) from text.\n",
    "     ```python\n",
    "     from nltk.util import ngrams\n",
    "     list(ngrams(tokens, 2))  # Bigrams\n",
    "     ```\n",
    "\n",
    "### 10. **Collocations**:\n",
    "   - **Finding Collocations**: Discover frequent word pairings.\n",
    "     ```python\n",
    "     from nltk.collocations import BigramCollocationFinder\n",
    "     finder = BigramCollocationFinder.from_words(tokens)\n",
    "     finder.nbest(nltk.BigramAssocMeasures().pmi, 10)  # Top 10 collocations\n",
    "     ```\n",
    "\n",
    "### 11. **WordNet (Lexical Database)**:\n",
    "   - **Synsets**: Get the synonym sets of a word.\n",
    "     ```python\n",
    "     from nltk.corpus import wordnet\n",
    "     synsets = wordnet.synsets('word')\n",
    "     ```\n",
    "   - **Definitions**: Get the definition of a word.\n",
    "     ```python\n",
    "     synsets[0].definition()\n",
    "     ```\n",
    "   - **Antonyms & Synonyms**: Find antonyms or synonyms.\n",
    "     ```python\n",
    "     wordnet.synsets('good')[0].lemmas()[0].antonyms()\n",
    "     ```\n",
    "\n",
    "### 12. **Text Classification**:\n",
    "   - **Naive Bayes Classifier**: Train a Naive Bayes model for classification tasks.\n",
    "     ```python\n",
    "     from nltk.classify import NaiveBayesClassifier\n",
    "     classifier = NaiveBayesClassifier.train(training_data)\n",
    "     classifier.classify(features)\n",
    "     ```\n",
    "\n",
    "### 13. **Corpus Access**:\n",
    "   - **Accessing Preloaded Corpora**: NLTK provides access to several corpora.\n",
    "     ```python\n",
    "     from nltk.corpus import gutenberg\n",
    "     gutenberg.raw('austen-emma.txt')\n",
    "     ```\n",
    "\n",
    "### 14. **Language Modeling**:\n",
    "   - **Conditional Frequency Distribution**: Useful for language modeling tasks.\n",
    "     ```python\n",
    "     from nltk.probability import ConditionalFreqDist\n",
    "     cfd = ConditionalFreqDist((word1, word2) for word1, word2 in bigrams)\n",
    "     ```\n",
    "\n",
    "### 15. **Translation & Word Alignment**:\n",
    "   - **IBM Model for Word Alignment**: Used for bilingual word alignments.\n",
    "     ```python\n",
    "     from nltk.translate import IBMModel1\n",
    "     ```\n",
    "\n",
    "### 16. **Evaluation & Metrics**:\n",
    "   - **Accuracy**: Evaluate accuracy of a classifier.\n",
    "     ```python\n",
    "     nltk.classify.accuracy(classifier, test_set)\n",
    "     ```\n",
    "\n",
    "### 17. **Tokenizers & Text Processing**:\n",
    "   - **Regex Tokenizer**: Tokenizes text using regular expressions.\n",
    "     ```python\n",
    "     from nltk.tokenize import regexp_tokenize\n",
    "     regexp_tokenize(text, pattern)\n",
    "     ```\n",
    "\n",
    "### 18. **Sentiment Analysis**:\n",
    "   - **VADER Sentiment Analyzer**: Perform simple sentiment analysis.\n",
    "     ```python\n",
    "     from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "     sia = SentimentIntensityAnalyzer()\n",
    "     sia.polarity_scores(\"This is a good movie\")\n",
    "     ```\n",
    "\n",
    "### 19. **Text Similarity**:\n",
    "   - **Jaccard Similarity**: Calculate text similarity.\n",
    "     ```python\n",
    "     from nltk.metrics import jaccard_distance\n",
    "     jaccard_distance(set1, set2)\n",
    "     ```\n",
    "\n",
    "### 20. **Translation & BLEU Score**:\n",
    "   - **BLEU Score for Translation**: Compute translation quality score.\n",
    "     ```python\n",
    "     from nltk.translate.bleu_score import sentence_bleu\n",
    "     sentence_bleu(reference, candidate)\n",
    "     ```\n",
    "\n",
    "### 21. **Chunking (Shallow Parsing)**:\n",
    "   - **Regexp Parser for Chunking**: Extract noun phrases or other chunks.\n",
    "     ```python\n",
    "     nltk.RegexpParser(grammar)\n",
    "     ```\n",
    "\n",
    "### How to Explore More Functions:\n",
    "\n",
    "To explore more functions in **NLTK**, you can:\n",
    "- Visit the **[official NLTK documentation](https://www.nltk.org/api/nltk.html).\n",
    "- Explore the source code by loading an interactive Python session and using `dir()` to list available methods:\n",
    "  ```python\n",
    "  import nltk\n",
    "  dir(nltk)\n",
    "  ```\n",
    "\n",
    "### Conclusion:\n",
    "NLTK offers a wide range of tools and functions for various NLP tasks, from basic preprocessing to advanced tasks like classification, parsing, and machine translation. Depending on the task, you can leverage different modules and functions to suit your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5fcae4-a87e-4a9e-a013-8b1a2cecc4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "There are many functions and modules in NLTK that go beyond the commonly used ones. Below are additional functions categorized by their specific purposes that I haven’t yet covered in the previous list:\n",
    "\n",
    "### 1. **Advanced Corpus Handling**:\n",
    "   - **Concordance**: Shows the context of a word within a corpus.\n",
    "     ```python\n",
    "     text.concordance('word')\n",
    "     ```\n",
    "   - **Word Context Index**: Finds all the occurrences of a word in a text.\n",
    "     ```python\n",
    "     nltk.text.ContextIndex(tokens)\n",
    "     ```\n",
    "   - **Collocations using TextCorpus**:\n",
    "     ```python\n",
    "     text.collocations()\n",
    "     ```\n",
    "\n",
    "### 2. **Semantic Processing**:\n",
    "   - **Semantic Role Labeling**: Determines roles of words in a sentence.\n",
    "     ```python\n",
    "     nltk.sem()  # General semantic processing\n",
    "     ```\n",
    "   - **VerbNet**: Access to verb-specific information.\n",
    "     ```python\n",
    "     from nltk.corpus import verbnet\n",
    "     verbnet.classids('run')\n",
    "     ```\n",
    "\n",
    "### 3. **Discourse Analysis**:\n",
    "   - **Discourse Representation**: Representing discourse semantics.\n",
    "     ```python\n",
    "     from nltk.sem import discourse\n",
    "     discourse.Discourse()\n",
    "     ```\n",
    "\n",
    "### 4. **Classification & Machine Learning**:\n",
    "   - **Decision Tree Classifier**: Used for text classification tasks.\n",
    "     ```python\n",
    "     from nltk.classify import DecisionTreeClassifier\n",
    "     ```\n",
    "   - **MaxEnt Classifier**: A maximum entropy model for classification.\n",
    "     ```python\n",
    "     from nltk.classify import MaxentClassifier\n",
    "     ```\n",
    "\n",
    "### 5. **Chunking**:\n",
    "   - **Named Entity Chunker**: For named entity recognition with trained models.\n",
    "     ```python\n",
    "     nltk.chunk.NamedEntityChunker()\n",
    "     ```\n",
    "\n",
    "### 6. **Parsing & Syntax Tree**:\n",
    "   - **Chart Parser**: A different method for parsing syntax trees.\n",
    "     ```python\n",
    "     nltk.ChartParser(grammar)\n",
    "     ```\n",
    "   - **Shift-Reduce Parser**: Another parsing method.\n",
    "     ```python\n",
    "     nltk.ShiftReduceParser(grammar)\n",
    "     ```\n",
    "\n",
    "### 7. **Probability Distributions**:\n",
    "   - **Laplace ProbDist**: Used for smoothing in probabilistic models.\n",
    "     ```python\n",
    "     from nltk.probability import LaplaceProbDist\n",
    "     ```\n",
    "   - **MLEProbDist**: Maximum likelihood estimate of a distribution.\n",
    "     ```python\n",
    "     from nltk.probability import MLEProbDist\n",
    "     ```\n",
    "\n",
    "### 8. **Taggers**:\n",
    "   - **Unigram Tagger**: Tags each token with its most common tag.\n",
    "     ```python\n",
    "     nltk.UnigramTagger()\n",
    "     ```\n",
    "   - **Bigram Tagger**: Tags tokens based on pairs of words.\n",
    "     ```python\n",
    "     nltk.BigramTagger()\n",
    "     ```\n",
    "   - **Brill Tagger**: A more advanced rule-based tagger.\n",
    "     ```python\n",
    "     nltk.BrillTagger()\n",
    "     ```\n",
    "\n",
    "### 9. **Language Models**:\n",
    "   - **NgramModel**: Models for computing probabilities based on N-grams.\n",
    "     ```python\n",
    "     nltk.model.NgramModel()\n",
    "     ```\n",
    "   - **PCFG Grammar**: Probabilistic context-free grammars.\n",
    "     ```python\n",
    "     nltk.PCFG.fromstring(grammar)\n",
    "     ```\n",
    "\n",
    "### 10. **Parsing with CFG**:\n",
    "   - **Context-Free Grammar (CFG)**: For defining grammars used in parsing.\n",
    "     ```python\n",
    "     nltk.CFG.fromstring(grammar)\n",
    "     ```\n",
    "\n",
    "### 11. **Morphology**:\n",
    "   - **Morphological Parsing**: For parsing complex word forms.\n",
    "     ```python\n",
    "     nltk.morphy()\n",
    "     ```\n",
    "\n",
    "### 12. **Metrics & Evaluation**:\n",
    "   - **Precision, Recall, F-measure**: Used for evaluation of classifiers.\n",
    "     ```python\n",
    "     from nltk.metrics import precision, recall, f_measure\n",
    "     precision(reference_set, test_set)\n",
    "     recall(reference_set, test_set)\n",
    "     f_measure(reference_set, test_set)\n",
    "     ```\n",
    "   - **Confusion Matrix**: Generates a confusion matrix for classification results.\n",
    "     ```python\n",
    "     from nltk.metrics import ConfusionMatrix\n",
    "     cm = ConfusionMatrix(reference_list, test_list)\n",
    "     ```\n",
    "\n",
    "### 13. **NLP Data Processing**:\n",
    "   - **Text Normalization**: Various utilities for text normalization.\n",
    "     ```python\n",
    "     from nltk import normalize\n",
    "     ```\n",
    "   - **Punkt Sentence Tokenizer**: A pre-trained tokenizer based on unsupervised learning.\n",
    "     ```python\n",
    "     nltk.tokenize.punkt.PunktSentenceTokenizer()\n",
    "     ```\n",
    "\n",
    "### 14. **Language Translation**:\n",
    "   - **Alignment Tools**: For bilingual word alignments.\n",
    "     ```python\n",
    "     from nltk.translate import Alignment\n",
    "     ```\n",
    "   - **Phrase-Based Machine Translation**:\n",
    "     ```python\n",
    "     nltk.translate.PhraseTable()\n",
    "     ```\n",
    "\n",
    "### 15. **Additional Tools**:\n",
    "   - **Edit Distance**: Used for spell checking or calculating distance between strings.\n",
    "     ```python\n",
    "     nltk.edit_distance('kitten', 'sitting')\n",
    "     ```\n",
    "   - **Bigrams/Trigrams from TextCorpus**:\n",
    "     ```python\n",
    "     text.collocations()\n",
    "     ```\n",
    "\n",
    "### 16. **Corpora Tools**:\n",
    "   - **Swadesh Corpus**: Vocabulary lists for language comparison.\n",
    "     ```python\n",
    "     from nltk.corpus import swadesh\n",
    "     swadesh.words('en')\n",
    "     ```\n",
    "   - **Indian Corpus**: Specific corpus for Indian languages.\n",
    "     ```python\n",
    "     from nltk.corpus import indian\n",
    "     indian.raw('hindi.pos')\n",
    "     ```\n",
    "\n",
    "### 17. **Miscellaneous**:\n",
    "   - **Conditional Probability Distribution**: For probabilistic models.\n",
    "     ```python\n",
    "     from nltk.probability import ConditionalProbDist\n",
    "     ```\n",
    "   - **Hidden Markov Model (HMM)**: Used for POS tagging and sequence labeling.\n",
    "     ```python\n",
    "     nltk.tag.hmm.HiddenMarkovModelTrainer()\n",
    "     ```\n",
    "\n",
    "---\n",
    "\n",
    "To explore additional functions in more detail, I recommend checking the NLTK source code or using the following approach:\n",
    "- **Use the `help()` Function**: You can find detailed information about any module or function in NLTK.\n",
    "  ```python\n",
    "  import nltk\n",
    "  help(nltk)\n",
    "  ```\n",
    "- **Check Documentation**: Visit the official [NLTK Documentation](https://www.nltk.org/).\n",
    "\n",
    "While this is a comprehensive list, NLTK is extensive, and some of its tools are not frequently used. Depending on your task, the functions you might need can vary significantly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
